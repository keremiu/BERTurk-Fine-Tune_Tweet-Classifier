training_tweets_csv_path: C:\Users\kerem\OneDrive\BERT\BERTurk-Fine-Tune_Tweet-Classifier\training_multilabel.csv #training_tweets.csv     # This set will be used by the Trainer class' test() method. Validation set will also be fractured out of this dataset
test_tweets_csv_path: C:\Users\kerem\OneDrive\BERT\BERTurk-Fine-Tune_Tweet-Classifier\training_multilabel.csv #test_tweets.csv             # A seperate test dataset that will be used by the Trainer class' test() method

# Dataset:
# The dataset must have the two columns of "text" and "label" in which the "text" column contains the tweets and "label" column contains the label(s)
# Both "text" and "label" columns must hold the string data type
# If an entry has multiple labels, then the labels in the "label" column should be seperated with a comma (,)
# A label cannot have blank spaces ( ), quotation marks ('' or "") and brackets ({} or []) in its name. 

model_path:                 # The model that is going to be used by the Trainer class' test() method. Leave empty if you want to use the model saved by the current process

device: cuda                # cuda or cpu

model_parameters:
  bert_model_name: dbmdz/bert-base-turkish-128k-cased
  layers: [                                               # Data is forwarded into these layers in the order of their indicies
    {"name": "linear", "in": 768, "out": 264},
    {"name": "linear", "in": 264, "out": 80},
    {"name": "linear", "in": 80, "out": 29},
  ]

# Available Layers: 
#   Linear:   {'name': 'linear', 'in': input_size, 'out': output_size}
#   Dropout:  {'name': 'dropout', 'p': dropout_probability}
#   Softmax:  {'name': 'softmax'}
#   Sigmoid:  {'name': 'sigmoid'}
#   ReLU:     {'name': 'relu'}

training_parameters:
  validation_size: 0.25      # A percentage between 0 and 1
  batch_size: 1
  learning_rate: 0.00002               #0.00002
  class_weights: True       # True or False
  optimizer: ADAM           # SGD or ADAM
  scheduler:                # Leave empty to disable
  num_epochs: 50

evaluation_parameters:
  threshold: 0.15